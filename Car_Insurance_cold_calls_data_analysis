Problem 1: Data Loading
------------------------

# Question 1: Load the data into a Hive table. Create an external table with the given schema and load the data into the table from a text file or HDFS path.

Query:
CREATE EXTERNAL TABLE car_insurance_cold_calls
(  id INT,
   Age INT,
   Job STRING,
   Marital STRING,
   Education STRING,
   Default INT,
   Balance INT,
   HHInsurance INT,
   CarLoan INT,
   Communication STRING,
   LastContactDay INT,
   LastContactMonth STRING,
   NoOfContacts INT,
   DaysPassed INT,
   PrevAttempts INT,
   Outcome STRING,
   CallStart STRING,
   CallEnd STRING,
   CarInsurance INT
)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS TextFile
LOCATION '/input_data/'
TBLPROPERTIES ("skip.header.line.count"="1");

Problem 2: Data Exploration
---------------------------

# Question 2:  How many records are there in the dataset?

-- to print header of the table, we have to enable below property:
SET hive.cli.print.header = true;

Query:
SELECT COUNT(*) AS total_records 
FROM car_insurance_cold_calls;

Analysis: 
There are 4000 records in the given dataset.

# Question 3: How many unique job categories are there?

Query:
SELECT COUNT(DISTINCT(Job)) AS job_categories 
FROM car_insurance_cold_calls;

Analysis: 
There are 12 unique job categories in the dataset.

# Question 4: What is the age distribution of customers in the dataset? Provide a breakdown by age group: 18-30, 31-45, 46-60, 61+.

Query:
WITH age_grp AS (
SELECT 
CASE WHEN Age >= 18 AND Age <= 30 THEN '18-30'
     WHEN Age >= 31 AND Age <= 45 THEN '31-45'
     WHEN Age >= 46 AND Age <= 60 THEN '46-60'
ELSE '61+'
END AS Age_group
FROM car_insurance_cold_calls
) 

SELECT Age_group, COUNT(*) AS age_distribution 
FROM age_grp
GROUP BY Age_group;

Analysis:
age_group       age_distribution
---------------------------------
18-30           678
31-45           2003
46-60           1129
61+             190

# Question 5: Determine the number of unique 'Outcome' values and their respective counts.

Query: 
SELECT Outcome, COUNT(*) AS count
FROM car_insurance_cold_calls
GROUP BY Outcome;

Analysis:
outcome  count
---------------
NA       3042
failure  437
other    195
success  326

# Question 6: Find the number of customers who have both a car loan and home insurance?

Query:
SELECT COUNT(*) FROM car_insurance_cold_calls
WHERE (carloan = 1) AND (HHInsurance = 1);

Analysis:
There are 322 customers in the dataset who have both a car loan and home insurance.

Problem 3: Aggregations
-----------------------

# Question 7: What is the average, minimum, and maximum balance for each job category?

Query: 
SELECT Job, 
       ROUND(AVG(balance),2) AS avg_balance,
       MIN(balance) AS min_balance,
       MAX(balance) AS max_balance
FROM car_insurance_cold_calls
GROUP BY Job;

Analysis:
Job               avg_balance     min_balance     max_balance
---------------------------------------------------------------
NA                1129.63         -295             4465
admin.            1212.04         -982             19213
blue-collar       1216.96         -931             21522
entrepreneur      1689.15         -799             27624
housemaid         859.72          -278             4312
management        2135.26         -1246            98417
retired           2267.39         -1206            37127
self-employed     1964.59         -3058            52587
services          851.42          -1730            11516
student           1420.84         -679             23878
technician        1414.69         -1317            45248
unemployed        1423.02         -581             17747

# Question 8: Find the total number of customers with and without car insurance?

Query:
SELECT CarInsurance, 
       COUNT(*) AS num_customers
FROM car_insurance_cold_calls
GROUP BY CarInsurance;

Analysis:
-- O means No and 1 means YES.

carinsurance    num_customers
0                2396
1                1604

# Question 9: Count the number of customers for each communication type?

Query:
SELECT COALESCE(Communication, 'Others'),
       COUNT(*) AS total_customers
FROM car_insurance_cold_calls
GROUP BY Communication;

Analysis:
communication    total_customers
-----------------------------------
NA               902
cellular         2831
telephone        267

# Question 10: Calculate the sum of 'Balance' for each 'Communication' type?

Query:
SELECT Communication, 
       SUM(Balance) AS total_balance
FROM car_insurance_cold_calls
GROUP BY Communication;

Analysis:
communication   total_balance
------------------------------
NA               1091772
cellular         4464294
telephone        575683

# Question 11: Count the number of 'PrevAttempts' for each 'Outcome' type?

Query:
SELECT Outcome,
       COUNT(PrevAttempts) AS prev_attempts_count
FROM car_insurance_cold_calls
GROUP BY Outcome;

Analysis:
outcome       prev_attempts_count
----------------------------------
NA               3042
failure          437
other            195
success          326

# Question 12: Calculate the average 'NoOfContacts' for people with and without 'CarInsurance'.

Query:
SELECT CarInsurance, 
       ROUND(AVG(NoOfContacts),2) AS avg_num_contacts
FROM car_insurance_cold_calls
GROUP BY CarInsurance;

Analysis:
-- O means No and 1 means YES.

carinsurance    avg_num_contacts
-----------------------------------
0                   2.9
1                   2.18

Problem 4: Partitioning and Bucketing
--------------------------------------

# Question 13: Create a partitioned table on 'Education' and 'Marital' status. Load data from the original table to this new partitioned table

-- To enable dynamic partitioning in Hive, set below mentioned property:
SET hive.exec.dynamic.partition = true;
SET hive.exec.dynamic.partition.mode = nonstrict;

Query:
CREATE TABLE car_insurance_multilevel_partitioned
(  id INT,
   Age INT,
   Job STRING,
   Default INT,
   Balance INT,
   HHInsurance INT,
   CarLoan INT,
   Communication STRING,
   LastContactDay INT,
   LastContactMonth STRING,
   NoOfContacts INT,
   DaysPassed INT,
   PrevAttempts INT,
   Outcome STRING,
   CallStart STRING,
   CallEnd STRING,
   CarInsurance INT
)
PARTITIONED BY (Education STRING, Marital STRING)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS TextFile
TBLPROPERTIES ("skip.header.line.count"="1");

-- Loading data into the car_insurance_multilevel_partitioned table
INSERT OVERWRITE TABLE car_insurance_multilevel_partitioned PARTITION (Education, Marital) 
SELECT id, Age, Job, Default, Balance, HHInsurance, CarLoan, Communication, 
       LastContactDay, LastContactMonth, NoOfContacts, DaysPassed, PrevAttempts, Outcome, CallStart, 
       CallEnd, CarInsurance, Education, Marital 
FROM car_insurance_cold_calls;

Analysis:
-- We can see that in hive warehouse directory, parititions have been created for each education category.
aspiringde2306@hadoop-cluster-m:~$ hdfs dfs -ls /user/hive/warehouse/hive_assignments.db/car_insurance_multilevel_partitioned
Found 4 items
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 11:02 /user/hive/warehouse/hive_assignments.db/car_insurance_multilevel_partitioned/education=NA
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 11:02 /user/hive/warehouse/hive_assignments.db/car_insurance_multilevel_partitioned/education=primary
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 11:02 /user/hive/warehouse/hive_assignments.db/car_insurance_multilevel_partitioned/education=secondary
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 11:02 /user/hive/warehouse/hive_assignments.db/car_insurance_multilevel_partitioned/education=tertiary

# Question 14: Create a bucketed table on 'Age', bucketed into 4 groups (as per the age groups mentioned above). Load data from the original table into this bucketed table.

Query:
-- To use Bucketing in hive, enable below property:
SET hive.enforce.bucketing = true;

CREATE TABLE car_insurance_cold_calls_bucketed
(  id INT,
   Age INT,
   Job STRING,
   Marital STRING,
   Education STRING,
   Default INT,
   Balance INT,
   HHInsurance INT,
   CarLoan INT,
   Communication STRING,
   LastContactDay INT,
   LastContactMonth STRING,
   NoOfContacts INT,
   DaysPassed INT,
   PrevAttempts INT,
   Outcome STRING,
   CallStart STRING,
   CallEnd STRING,
   CarInsurance INT
)
CLUSTERED BY (Age) INTO 4 BUCKETS
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS TextFile
TBLPROPERTIES ("skip.header.line.count"="1");

-- Loading data into the car_insurance_cold_calls_bucketed table
INSERT OVERWRITE TABLE car_insurance_cold_calls_bucketed SELECT * FROM car_insurance_cold_calls;

Analysis:
-- We can see that in hive warehouse directory 4 buckets have been created on the basis of age.
aspiringde2306@hadoop-cluster-m:~$ hdfs dfs -ls /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed
Found 4 items
-rw-r--r--   2 aspiringde2306 hadoop      86042 2023-11-18 11:22 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed/000000_0
-rw-r--r--   2 aspiringde2306 hadoop      68722 2023-11-18 11:22 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed/000001_0
-rw-r--r--   2 aspiringde2306 hadoop      92220 2023-11-18 11:22 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed/000002_0
-rw-r--r--   2 aspiringde2306 hadoop     116620 2023-11-18 11:22 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed/000003_0

# Question 15: Add an additional partition on 'Job' to the partitioned table created earlier and move the data accordingly.

Query:
-- If we want to add an additional partition based on the 'Job' column to the existing partitioned table, we have to create new partitioned table and transfer the data. 
   Hive doesn't support altering the partitioning of existing tables. 

CREATE TABLE car_insurance_cold_calls_partitioned
(  id INT,
   Age INT,
   Default INT,
   Balance INT,
   HHInsurance INT,
   CarLoan INT,
   Communication STRING,
   LastContactDay INT,
   LastContactMonth STRING,
   NoOfContacts INT,
   DaysPassed INT,
   PrevAttempts INT,
   Outcome STRING,
   CallStart STRING,
   CallEnd STRING,
   CarInsurance INT
)
PARTITIONED BY (Education STRING, Marital STRING, Job STRING)
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS TextFile
TBLPROPERTIES ("skip.header.line.count"="1");

-- Loading data into the car_insurance_cold_calls_partitioned table
INSERT OVERWRITE TABLE car_insurance_cold_calls_partitioned PARTITION (Education, Marital, Job) 
SELECT 
  id, Age, Default, Balance, HHInsurance, CarLoan, Communication,
  LastContactDay, LastContactMonth, NoOfContacts, DaysPassed, PrevAttempts, Outcome,
  CallStart, CallEnd, CarInsurance, Education, Marital, Job
FROM car_insurance_multilevel_partitioned;

-- Loading process may be failed if it creates dynamic partitions beyond limits, we can resolve this error by configuring below two properties:
SET hive.exec.max.dynamic.partitions=200;
SET hive.exec.max.dynamic.partitions.pernode=200;

Analysis: 
-- We can observe that multi-level partioning has been occured in hive warehouse directory

aspiringde2306@hadoop-cluster-m:~$ hdfs dfs -ls /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned
Found 4 items
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=NA
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=primary
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=tertiary

aspiringde2306@hadoop-cluster-m:~$ hdfs dfs -ls /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary
Found 3 items
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=married
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=single

aspiringde2306@hadoop-cluster-m:~$ hdfs dfs -ls /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced
Found 11 items
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=NA
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=admin.
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=blue-collar
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=entrepreneur
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=housemaid
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=management
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=retired
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=self-employed
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=services
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=technician
drwxr-xr-x   - aspiringde2306 hadoop          0 2023-11-18 13:05 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_partitioned/education=secondary/marital=divorced/job=unemployed

# Question 16: Increase the number of buckets in the bucketed table to 10 and redistribute the data.

Query: 
-- In Hive, once a table is bucketed, the allocated number of buckets remains fixed and cannot be altered. Bucketing is an immutable process that occurs during table creation. 
   To increase the number of buckets, a new table must be created with the desired bucket count, and data must be inserted from the existing table into the new one.

CREATE TABLE car_insurance_cold_calls_bucketed_new
(  id INT,
   Age INT,
   Job STRING,
   Marital STRING,
   Education STRING,
   Default INT,
   Balance INT,
   HHInsurance INT,
   CarLoan INT,
   Communication STRING,
   LastContactDay INT,
   LastContactMonth STRING,
   NoOfContacts INT,
   DaysPassed INT,
   PrevAttempts INT,
   Outcome STRING,
   CallStart STRING,
   CallEnd STRING,
   CarInsurance INT
)
CLUSTERED BY (Age) INTO 10 BUCKETS
ROW FORMAT DELIMITED 
FIELDS TERMINATED BY ','
STORED AS TextFile
TBLPROPERTIES ("skip.header.line.count"="1");

-- Loading data into the new car_insurance_cold_calls_bucketed_new table
INSERT OVERWRITE TABLE car_insurance_cold_calls_bucketed_new SELECT * FROM car_insurance_cold_calls_bucketed;

Analysis:
-- We can see that 10 new buckets have been created inside hive warehouse directory

aspiringde2306@hadoop-cluster-m:~$ hdfs dfs -ls /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new
Found 10 items
-rw-r--r--   2 aspiringde2306 hadoop      36610 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000000_0
-rw-r--r--   2 aspiringde2306 hadoop      45278 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000001_0
-rw-r--r--   2 aspiringde2306 hadoop      30246 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000002_0
-rw-r--r--   2 aspiringde2306 hadoop      21704 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000003_0
-rw-r--r--   2 aspiringde2306 hadoop      63282 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000004_0
-rw-r--r--   2 aspiringde2306 hadoop      76249 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000005_0
-rw-r--r--   2 aspiringde2306 hadoop       3812 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000006_0
-rw-r--r--   2 aspiringde2306 hadoop      24373 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000007_0
-rw-r--r--   2 aspiringde2306 hadoop      44142 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000008_0
-rw-r--r--   2 aspiringde2306 hadoop      17548 2023-11-18 13:16 /user/hive/warehouse/hive_assignments.db/car_insurance_cold_calls_bucketed_new/000009_0


















